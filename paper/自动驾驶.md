# 自动驾驶

**目录**

[**3D目标检测**](#3D目标检测)

[**感知预测规划**](#感知预测规划)

[**追踪**](#追踪)

[**定位**](#定位)

[**Occupancy预测**](#Occupancy预测)

## 3D目标检测

<a name="3D目标检测"></a> 

### 雷达 激光雷达

- 标题：[RaLiBEV：用于无锚箱物体检测系统的雷达和LiDAR BEV融合学习](https://arxiv.org/pdf/2211.06108.pdf)
- 标题：[Bi-LRFusion：用于 3D 动态物体检测的双向 LiDAR-雷达融合](https://arxiv.org/pdf/2306.01438.pdf)
- 标题：[MaskBEV：鸟瞰图3D点云的联合对象检测和足迹完成](https://arxiv.org/pdf/2307.01864.pdf)
- 标题：[LXL：LiDAR 排除了采用4D成像雷达和相机融合的精益 3D 物体检测](https://arxiv.org/pdf/2307.00724.pdf)

### 雷达摄像头

- 标题：[CRAFT：使用空间上下文融合变压器进行摄像头雷达 3D 物体检测](https://arxiv.org/pdf/2209.06535.pdf)
- 标题：[RadSegNet：一种可靠的雷达相机融合方法](https://arxiv.org/pdf/2208.03849.pdf)
- 标题：[弥合雷达和相机功能的视图差异以实现多模态融合 3D 物体检测](https://arxiv.org/pdf/2208.12079.pdf)
- 标题：[CRN：用于准确、稳健、高效3D感知的相机雷达网络](https://arxiv.org/pdf/2304.00670.pdf)
- 标题：[RC-BEVFusion：雷达相机鸟眼视图功能融合的插件模块](https://arxiv.org/pdf/2305.15883.pdf)

### 激光雷达相机

- 标题：[语义融合：重新思考用于 3D 对象检测的统一鸟瞰图表示中的激光雷达-相机融合](https://arxiv.org/pdf/2212.04675.pdf)
- 标题：[用于3D目标检测的稀疏密集融合](https://arxiv.org/pdf/2304.04179.pdf)
- 标题：[EA-BEV：用于3D物体检测的边缘感知鸟眼投影仪](https://arxiv.org/pdf/2303.17895.pdf)
- 标题：[MSMDFusion：通过多深度种子在多个尺度上融合 LiDAR 和相机以进行 3D 物体检测](https://arxiv.org/pdf/2209.03102.pdf)
- 标题：[FULLER：通过多级梯度校准实现统一多模态多任务3D感知](https://arxiv.org/pdf/2307.16617.pdf)
- 标题：[重新思考 3D 物体检测中的 LiDAR-相机融合](https://arxiv.org/pdf/2311.07152.pdf)
- 标题：[SupFusion：用于3D物体检测的监督 LiDAR-相机融合](https://arxiv.org/pdf/2309.07084.pdf)
- 标题：[3DifFusionDet：使用稳健的LiDAR-相机融合进行3D物体检测的扩散模型](https://arxiv.org/pdf/2311.03742.pdf)
- 标题：[FUSIONVIT：通过激光雷达-相机视觉变压器融合进行分层 3D 物体检测](https://arxiv.org/pdf/2311.03620.pdf)

### 激光雷达

- 标题：[MGTANet：使用长短期运动引导时间注意力对连续LiDAR点进行编码以进行3D对象检测](https://arxiv.org/pdf/2212.00442.pdf)
- 标题：[提升LiDAR 3D物体检测的极地表示](https://arxiv.org/pdf/2308.03982.pdf)
- 标题：[V-DETR：用于3D对象检测的具有顶点相对位置编码的DETR](https://arxiv.org/pdf/2308.04409.pdf)

### 单目

- 标题：[学习2D到3D提升以进行3D自主车辆物体检测](https://arxiv.org/abs/1904.08494)
- 标题：[用于单目 3D 物体检测的正交特征变换](http://mi.eng.cam.ac.uk/~cipolla/publications/inproceedings/2019-BMVC-Orthographic-Feature-Transform.pdf)
- 标题：[BEV-MODNet：用于自动驾驶的基于单目摄像头的鸟瞰移动物体检测](https://arxiv.org/abs/2107.04937)
- 标题：[用于单目3D物体检测的分类深度分布网络](https://openaccess.thecvf.com/content/CVPR2021/papers/Reading_Categorical_Depth_Distribution_Network_for_Monocular_3D_Object_Detection_CVPR_2021_paper.pdf)
- 标题：[PersDet：鸟瞰视角中的单目3D检测](https://arxiv.org/pdf/2208.09394.pdf)
- 标题：[Time3D：用于自动驾驶的端到端联合单目3D物体检测和跟踪](https://arxiv.org/pdf/2205.14882.pdf)
- 标题：[具有运动深度的单目3D物体检测](https://arxiv.org/pdf/2207.12988.pdf)
- 标题：[MonoNeRD：单目 3D 物体检测的类 NeRF 表示](https://arxiv.org/pdf/2308.09421v1.pdf)
- 标题：[S3-MonoDETR：用于单目3D物体检测的监督形状和尺度感知Transformer](https://arxiv.org/pdf/2309.00928.pdf)
- 标题：[MonoGAE：具有地面感知嵌入的路边单目3D物体检测](https://arxiv.org/pdf/2310.00400.pdf)
- 标题：[YOLO-BEV：以与2D物体检测相同的方式生成鸟瞰图](https://arxiv.org/pdf/2310.17379.pdf)

### 多目

- 标题：[SRCN3D：用于自动驾驶的稀疏 R-CNN3D环视摄像头目标检测和跟踪](https://arxiv.org/abs/2206.14451)
- 标题：[BEVDet4D：在多摄像头3D目标检测中利用时间线索](https://arxiv.org/pdf/2203.17054.pdf)
- 标题：[BEVStereo：利用动态时间立体增强多视图3D目标检测中的深度估计](https://arxiv.org/abs/2209.10248)
- 标题：[MV-FCOS3D++：使用预训练的单目骨干网进行仅多视图相机的 4D物体检测](https://arxiv.org/pdf/2207.12716.pdf)
- 标题：[Focal-PETR：拥抱前景以实现高效的多相机3D对象](https://arxiv.org/pdf/2212.05505.pdf)
- 标题：[DETR4D：具有稀疏注意力的直接多视图3D目标检测](https://arxiv.org/pdf/2212.07849.pdf)
- 标题：[用于3D物体检测的多相机免校准 BEV 表示](https://arxiv.org/pdf/2210.17252.pdf)
- 标题：[SemanticBEVFusion：重新思考3D目标检测的统一鸟瞰视图表示中的LiDAR-相机融合](https://arxiv.org/pdf/2212.04675.pdf)
- 标题：[BEV-SAN：通过切片注意力网络进行准确的 BEV 3D目标检测](https://arxiv.org/pdf/2212.04675.pdf)
- 标题：[STS：用于多视图3D检测的环视时态立体](https://arxiv.org/abs/2208.10145)
- 标题：[BEV-LGKD：用于BEV 3D目标检测的统一LiDAR引导知识蒸馏框架](https://arxiv.org/pdf/2212.00623.pdf)
- 标题：[用于3D物体检测的多相机免校准BEV表示](https://arxiv.org/pdf/2210.17252.pdf)
- 标题：[Object as Query: 为任何2D对象检测器配备3D检测能力](https://arxiv.org/pdf/2301.02364.pdf)
- 标题：[VoxelFormer：基于双视图注意力的鸟瞰特征生成，用于多视图3D目标检测](https://github.com/Lizhuoling/VoxelFormer-public)
- 标题：[TiG-BEV：通过目标内部几何学习进行多视图BEV 3D目标检测](https://arxiv.org/pdf/2212.13979.pdf)
- 标题：[CrossDTR：用于 3D 对象检测的交叉视图和深度引导Transformer](https://arxiv.org/pdf/2209.13507.pdf)
- 标题：[SOLOFusion：时间会证明一切：时态多视图3D目标检测的新前景和基线](https://arxiv.org/abs/2210.02443)
- 标题：[BEVDistill：用于多视图3D目标检测的跨模态BEV蒸馏](https://openreview.net/pdf?id=-2zfgNS917)
- 标题：[UniDistill：鸟瞰3D目标检测的通用跨模态知识蒸馏框架](https://arxiv.org/pdf/2303.15083.pdf)
- 标题：[了解自动驾驶中鸟瞰图表示的3D目标检测的鲁棒性](https://arxiv.org/pdf/2303.17297.pdf)
- 标题：[Uni3D：多数据集3D目标检测的统一基线](https://arxiv.org/pdf/2303.06880.pdf)
- 标题：[Aedet：方位角不变的多视图3D目标检测](https://arxiv.org/pdf/2211.12501.pdf)
- 标题：[BEVHeight：基于视觉的路边3D目标检测的鲁棒框架](https://arxiv.org/pdf/2303.08498.pdf)
- 标题：[CAPE：用于多视图3D目标检测的相机视图位置嵌入](https://arxiv.org/pdf/2303.10209.pdf)
- 标题：[FrustumFormer：用于多视图3D检测的自适应实例感知重采样](https://arxiv.org/pdf/2301.04467.pdf)
- 标题：[Sparse4D v2与稀疏模型的循环时间融合](https://arxiv.org/pdf/2305.14018.pdf)
- 标题：[DA-BEV：用于3D物体检测的深度感知BEV Transformer](https://arxiv.org/pdf/2302.13002.pdf)
- 标题：[BEV-IO：通过实例占用增强鸟瞰3D检测](https://arxiv.org/pdf/2305.16829.pdf)
- 标题：[OCBEV：用于多视图3D目标检测的以对象为中心的 BEV Transformer](https://arxiv.org/pdf/2306.01738.pdf)
- 标题：[SA-BEV：生成用于多视图3D目标检测的语义感知鸟瞰图功能](https://arxiv.org/pdf/2307.11477.pdf)
- 标题：[预测检测：使用序列图像进行预测引导的3D目标检测](https://arxiv.org/pdf/2306.08528.pdf)
- 标题：[DFA3D：用于2D到3D特征提升的3D可变形注意力](https://arxiv.org/pdf/2307.12972.pdf)

## 感知预测规划

<a name="感知预测规划"></a> 

### 单目

- 标题：[在平板车中驾驶：单目摄像头鸟瞰占用网格，用于整体轨迹规划](https://openaccess.thecvf.com/content/WACV2021/papers/Loukkal_Driving_Among_Flatmobiles_Bird-Eye-View_Occupancy_Grids_From_a_Monocular_Camera_WACV_2021_paper.pdf)
- 标题：[HOPE：用于占用流量预测的分层时空网络](https://arxiv.org/pdf/2206.10118.pdf)

### 多相机

- 标题：[FIERY：环绕单目相机鸟瞰图的未来实例预测](https://openaccess.thecvf.com/content/ICCV2021/papers/Hu_FIERY_Future_Instance_Prediction_in_Birds-Eye_View_From_Surround_Monocular_ICCV_2021_paper.pdf)
- 标题：[NEAT：端到端自动驾驶的神经注意场](https://arxiv.org/pdf/2109.04456.pdf)
- 标题：[ST-P3：通过时空特征学习实现端到端的基于视觉的自主驾驶](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136980522.pdf)
- 标题：[StretchBEV：在空间和时间上拉伸未来实例预测](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136980436.pdf)
- 标题：[TBP-Former：学习时间鸟瞰金字塔以实现以视觉为中心的自动驾驶中的联合感知和预测](https://arxiv.org/pdf/2303.09998.pdf)
- 标题：[面向规划的自动驾驶（占格预测）](https://arxiv.org/pdf/2212.10156.pdf)
- 标题：[驾驶前三思而后行：面向端到端自动驾驶的可扩展解码器](https://arxiv.org/pdf/2305.06242.pdf)
- 标题：[ReasonNet：具有时间和全局推理的端到端驱动](https://arxiv.org/pdf/2305.10507.pdf)
- 标题：[LiDAR-BEVMTN：用于自动驾驶的实时 LiDAR 鸟瞰多任务感知网络](https://arxiv.org/pdf/2307.08850.pdf)
- 标题：[FusionAD：用于自动驾驶预测和规划任务的多模态融合](https://arxiv.org/pdf/2308.01006.pdf)

## 追踪

<a name="追踪"></a> 

- 标题：[使用 Transformer 探索用于 3D 点云对象跟踪的 Point-BEV Fusion](https://arxiv.org/pdf/2208.05216.pdf)
- 标题：[EarlyBird：鸟瞰多视图跟踪的早期融合](https://arxiv.org/pdf/2310.13350.pdf)

## 定位

<a name="定位"></a> 

- 标题：[BEV-Locator：使用多视图图像的端到端视觉语义定位网络](https://arxiv.org/pdf/2211.14927.pdf)
- 标题：[BEV-SLAM：使用单目视觉构建全球一致的世界地图](https://cvssp.org/Personal/OscarMendez/papers/pdf/RossIROS2022.pdf)
- 标题：[U-BEV：高度感知鸟瞰分割和基于神经图的重定位](https://arxiv.org/pdf/2310.13766.pdf)

## Occupancy预测

<a name="Occupancy预测"></a> 

- 标题：[占用网络：学习函数空间中的 3D 重建](https://arxiv.org/pdf/1812.03828.pdf)
- 标题：[3D 语义场景完成：综述](https://arxiv.org/pdf/2103.07466.pdf)
- 标题：[LiDAR 点云的语义分割辅助场景完成 ](https://arxiv.org/pdf/2109.11453.pdf)
- 标题：[自动驾驶以网格为中心的交通场景感知：全面回顾](https://arxiv.org/pdf/2303.01212.pdf)
- 标题：[LMSCNet：轻量级多尺度 3D 语义补全](https://arxiv.org/pdf/2008.10559.pdf)
- 标题：[MonoScene：单目 3D 语义场景补全](https://arxiv.org/pdf/2112.00726.pdf)
- 标题：[OccFormer：用于基于视觉的 3D 语义占用预测的双路径 Transformer](https://arxiv.org/pdf/2304.05316.pdf)
- 标题：[自动驾驶中3D占用估计的简单尝试](https://arxiv.org/pdf/2303.10076.pdf)
- 标题：[OccDepth：3D 语义占用网络的深度感知方法](https://arxiv.org/pdf/2302.13540.pdf)
- 标题：[OpenOccupancy：周围语义占用感知的大规模基准](https://arxiv.org/pdf/2303.03991.pdf)
- 标题：[Occ3D：自动驾驶大规模 3D 占用预测基准](https://arxiv.org/pdf/2304.14365.pdf)
- 标题：[Occ-BEV：通过 3DScene 重建进行多相机统一预训练](https://arxiv.org/pdf/2305.18829.pdf)
- 标题：[StereoScene：BEV 辅助立体匹配赋能 3D 语义场景完成](https://arxiv.org/pdf/2303.13959.pdf)
- 标题：[学习单目 3D 物体检测的占用率](https://arxiv.org/pdf/2305.15694.pdf)
- 标题：[OVO：开放词汇占用](https://arxiv.org/pdf/2305.16133.pdf)
- 标题：[SurroundOcc：自动驾驶的多摄像头 3D 占用预测](https://arxiv.org/pdf/2303.09551.pdf)
- 标题：[场景作为占用](https://arxiv.org/pdf/2301.00527.pdf) 
- 标题：[场景规模 3D 分类数据的扩散概率模型](https://arxiv.org/pdf/2301.00527.pdf)
- 标题：[PanoOcc：基于相机的 3D 全景分割的统一占用表示](https://arxiv.org/pdf/2306.10013.pdf)
- 标题：[UniOcc：通过几何和语义渲染统一以视觉为中心的 3D 占用预测](https://arxiv.org/pdf/2306.09117.pdf)
- 标题：[SSCBench：自动驾驶的大规模 3D 语义场景完成基准](https://arxiv.org/pdf/2306.09001.pdf)
- 标题：[StereoVoxelNet：使用深度神经网络基于立体相机的 OccupancyVoxels 进行实时障碍物检测]( https://arxiv.org/pdf/2209.08459.pdf)
- 标题：[基于视觉的 3D 语义占用预测的三视角视图](https://arxiv.org/pdf/2302.07817.pdf)
